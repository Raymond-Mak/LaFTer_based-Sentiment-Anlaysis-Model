### 1 ä¸ºä»€ä¹ˆå•ç‹¬åœ¨æœ€å‰é¢æ”¾ä¸€å±‚ prompt ä¸å¤Ÿ

Cascade-CLIP çš„å®éªŒæ˜¾ç¤ºï¼š

- **ä¸­å±‚ç‰¹å¾åŒ…å«ä¸°å¯Œçš„å±€éƒ¨ç»†èŠ‚**ï¼Œä½†ç›´æ¥æŠŠå¤šå±‚ç‰¹å¾ concat/fuse ä¼šç ´å CLIP é¢„è®­ç»ƒå¥½çš„è§†è§‰-è¯­è¨€å¯¹é½ï¼Œä»è€Œæ˜¾è‘—æ‰ç‚¹ ã€‚
    
- è§£å†³æ€è·¯æ˜¯**åˆ†æ®µå¯¹é½**ï¼šæŠŠè§†è§‰ç¼–ç å™¨æŒ‰æ·±åº¦åˆ‡æˆè‹¥å¹² stageï¼Œæ¯æ®µå•ç‹¬é…ä¸€ä¸ªè§£ç å™¨ï¼ˆæˆ–åˆ†ç±»å¤´ï¼‰ï¼Œæœ€åæŠŠæ‰€æœ‰ stage çš„è¾“å‡ºå†çº§è”èåˆ ã€‚
    

### 2 Cascade-CLIP çš„ NGAï¼ˆNeighborhood Gaussian Aggregationï¼‰æ ¸å¿ƒ

åœ¨ä¸€ä¸ª stage å†…ï¼Œå¯¹è¿ç»­çš„ Transformer block è¾“å‡ºä½¿ç”¨å¯è®­ç»ƒçš„é«˜æ–¯æƒé‡

Ws,l=eâˆ’(dâˆ’l+1)22Ïƒ2,Zs=âˆ‘l=1dHlâ‹…Ws,lW_{s,l}=e^{-\frac{(d-l+1)^{2}}{2\sigma^{2}}},\qquad Z_s=\sum_{l=1}^{d}H_l\cdot W_{s,l}

ä»¥**é‚»è¿‘å—æƒé‡å¤§ã€è¿œå¤„å—æƒé‡å°**çš„æ–¹å¼è‡ªé€‚åº”èšåˆç‰¹å¾ ã€‚  
è°ƒèŠ‚ Ïƒ å³å¯åœ¨ã€Œåªçœ‹å•å±‚ã€â†”ã€Œå¹³å‡æ‰€æœ‰å±‚ã€ä¹‹é—´å¹³æ»‘è¿‡æ¸¡ï¼›Ïƒ å¤ªå¤§æˆ–å¤ªå°éƒ½ä¼šæŸå¤±æ€§èƒ½ ã€‚

### 3 å°† **prompt-tuning** åµŒå…¥å¤šå±‚çš„å¯è¡Œæ–¹æ¡ˆï¼ˆé€‚é… LaFTerï¼‰

|æ­¥éª¤|è®¾è®¡è¦ç‚¹|è®­ç»ƒå‚æ•°|
|---|---|---|
|**3.1 è§†è§‰ç¼–ç å™¨åˆ†æ®µ**|ä»¥ ViT-B/16 ä¸ºä¾‹å¯ç”¨ {6-8}, {9-11}, {12} ä¸‰æ®µï¼šâ€¢ å‰ 1-5 å±‚ä¿æŒå†»ç»“ï¼Œé¿å…ä½çº§ç‰¹å¾è¢«æ‰°åŠ¨â€¢ æ¯æ®µåæ¥ _Pool/CLS_ + çº¿æ€§å¤´ï¼Œå°†å¾—åˆ°çš„é˜¶æ®µè¡¨å¾é€å…¥å·²è®­ç»ƒå¥½çš„ **text classifier**ï¼ˆå…±äº«æƒé‡ï¼‰|å†»ç»“ CLIP æƒé‡ï¼Œä»…è®­ prompt + èšåˆæƒé‡|
|**3.2 æ’å…¥åˆ†æ®µ prompt**|åœ¨æ¯ä¸ªæ®µ **å¼€å§‹å¤„**æ’å…¥ M ä¸ªå¯å­¦ä¹ è§†è§‰ prompt tokenï¼Œå†ä¸è¯¥æ®µè¾“å…¥ patch token concatã€‚å„æ®µ prompt å¯**ç‹¬ç«‹å‚æ•°**ï¼Œä¹Ÿå¯éƒ¨åˆ†å…±äº«ä»¥èŠ‚çœæ˜¾å­˜ã€‚è§†è§‰ prompt èƒ½æŠŠæ¢¯åº¦ç›´æ¥ä¼ åˆ°ä¸­å±‚ï¼Œä¿ƒè¿›è·¨å±‚å¯¹é½|prompt tokenï¼ˆæ¯æ®µ Mâ‰ˆ8-16ï¼‰|
|**3.3 NGA ç‰¹å¾æ±‡èš**|å¯¹åŒä¸€æ®µå†…å„ block çš„ _CLS_ æˆ– mean-pooled patch å…ˆåš LayerNormï¼Œå†ç”¨ NGA æƒé‡æ±‚åŠ æƒå’Œ å¾—åˆ° Z_s|Ïƒ=1 æ˜¯ç»éªŒä¸Šè¾ƒç¨³ï¼›Ïƒ å¯è®­ç»ƒ|
|**3.4 çº§è”åˆ¤åˆ«**|æŠŠ Z1,Z2,Z3Zâ‚,Zâ‚‚,Zâ‚ƒ é€šè¿‡**å¯å­¦ä¹ æƒé‡æˆ–ç®€æ˜“åŠ æƒæ±‚å’Œ**ï¼Œè¾“å…¥ text classifier å¾—åˆ°æœ€ç»ˆ logitsï¼›loss ä»ç”¨äº¤å‰ç†µï¼ˆå¯åŠ  KL æ­£åˆ™ä½¿å„æ®µè¾“å‡ºä¸€è‡´ï¼‰|æ®µé—´æƒé‡ Î»_s å¯è®­ç»ƒ|
|**3.5 è®­ç»ƒç­–ç•¥**|1. å†»ç»“ CLIP backboneï¼›2. å…ˆ warm-up åªè®­æœ€å‰æ®µçš„ prompt & classifierï¼›3. é€æ®µè§£å†» prompt+NGAï¼›4. å…¨å±€ fine-tune prompt+NGA+classifierï¼ˆ2-3 epoch å³å¯æ”¶æ•›ï¼‰|AdamW, lrâ‰ˆ1e-4ï¼Œä»…æ•°ç™¾ä¸‡å‚æ•°|

> **æ•ˆæœé¢„æœŸ**ï¼šç›¸æ¯”â€œå•å±‚ promptâ€ï¼Œåˆ†æ®µæ–¹æ¡ˆèƒ½åŒæ—¶åˆ©ç”¨æ·±å±‚è¯­ä¹‰ä¸ä¸­å±‚å±€éƒ¨ç»†èŠ‚ï¼›NGA ä¿ç•™é‚»è¿‘ä¿¡æ¯ã€å‡å°ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»ï¼Œå› æ­¤åˆ†ç±»å™¨æ”¶åˆ°çš„å¤šå°ºåº¦è¯­ä¹‰æ›´åŠ ç¨³å¥ã€‚Cascade-CLIP çš„æ¶ˆèä¹Ÿè¯æ˜ï¼šä»…é çº§è”æˆ–ä»…é  NGA å‡æ— æ³•è¾¾åˆ°ä¸¤è€…ç»“åˆçš„æ€§èƒ½æå‡ ã€‚

### 4 è½åœ°å»ºè®®ä¸æ³¨æ„äº‹é¡¹

1. **æ®µåˆ’åˆ†**ï¼šä¿æŒæ¯æ®µè‡³å°‘ 2-3 blockï¼Œæœ€åä¸€å±‚å•ç‹¬æˆæ®µå¯é˜²æ­¢å¯¹é½è¢«ç ´å ã€‚
    
2. **Prompt æ•°é‡**ï¼šåœ¨ LaFTer çš„åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œ35-50 ä¸ª token å·²èƒ½è¶…è¿‡ ZegCLIP ç”¨ 100 ä¸ª token çš„æ•ˆæœ ã€‚
    
3. **æ–‡æœ¬ä¾§ä¿æŒä¸å˜**ï¼šå› ä¸ºä½ ç¬¬äºŒé˜¶æ®µå·²ç”¨çœŸå®æ ‡ç­¾ç›‘ç£ text classifierï¼Œæ‰€ä»¥ä¸ç”¨åƒ Cascade-CLIP é‚£æ ·æ¯æ®µé…ç‹¬ç«‹ text embeddingï¼›åªéœ€ä¸€ä¸ªå…±äº« classifierï¼Œå‡å°‘å‚æ•°ã€‚
    
4. **ç›‘æ§å¯¹é½**ï¼šå¯å€ŸåŠ© centered-kernel-alignmentï¼ˆCKAï¼‰çŸ©é˜µè¯„ä¼°ä¸­å±‚ä¸æ·±å±‚ç‰¹å¾ç›¸ä¼¼åº¦ï¼›è‹¥å‘ç°å·®è·è¿‡å¤§ï¼Œå¯é€‚å½“æé«˜ Ïƒ æˆ–åŠ  layer-wise distillation lossã€‚
    
5. **æ¨ç†å¼€é”€**ï¼šä»…å¤šäº† prompt token ä¸æå°‘é‡ NGA æƒé‡ï¼Œæ˜¾å­˜ä¸é€Ÿåº¦æŸå¤±å¯å¿½ç•¥ä¸è®¡ï¼›ä»å¯ batch æ¨ç†ã€‚
    

æŒ‰ç…§ä»¥ä¸Šæ­¥éª¤ï¼Œä½ å¯ä»¥åœ¨ä¿æŒ LaFTer ç°æœ‰ä¸¤é˜¶æ®µæµç¨‹ä¸å˜çš„å‰æä¸‹ï¼ŒæŠŠ **Prompt â†’ å¤šå±‚åµŒå…¥ + NGA èšåˆ** æ— ç¼è¿å…¥ï¼Œå……åˆ†åˆ©ç”¨ CLIP Encoder çš„å±‚çº§è¡¨ç¤ºèƒ½åŠ›ï¼Œä¸ºä¸‹æ¸¸åˆ†ç±»å¸¦æ¥é¢å¤–æ”¶ç›Šã€‚ç¥å®éªŒé¡ºåˆ©!


















â— å¤šå±‚PromptæŠ€æœ¯åœ¨LaFTeré¡¹ç›®çš„è½åœ°æ–¹æ¡ˆ

  ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

  åŸºäºä½ çš„ViT-B/32æ¨¡å‹ï¼ˆ12å±‚ç»“æ„ï¼‰ï¼Œæˆ‘è®¾è®¡äº†ä¸€ä¸ªé’ˆå¯¹æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡çš„å¤šå±‚promptæŠ€æœ¯æ–¹æ¡ˆï¼Œå……åˆ†åˆ©ç”¨ä¸åŒå±‚çº§çš„ç‰¹å¾è¡¨ç¤ºèƒ½
  åŠ›ã€‚

  ğŸ—ï¸ æ ¸å¿ƒè®¾è®¡è¦ç‚¹

  1. ViT-B/32åˆ†æ®µç­–ç•¥ï¼ˆé’ˆå¯¹12å±‚ç»“æ„ï¼‰

  æ®µåˆ’åˆ†ï¼š{1-4}, {5-8}, {9-11}, {12}
  - ç¬¬1æ®µï¼ˆå±‚1-4ï¼‰ï¼šä½çº§ç‰¹å¾ï¼Œè¾¹ç¼˜å’Œçº¹ç†ä¿¡æ¯
  - ç¬¬2æ®µï¼ˆå±‚5-8ï¼‰ï¼šä¸­çº§ç‰¹å¾ï¼Œå±€éƒ¨æ¨¡å¼å’Œå¯¹è±¡éƒ¨ä»¶
  - ç¬¬3æ®µï¼ˆå±‚9-11ï¼‰ï¼šé«˜çº§ç‰¹å¾ï¼Œè¯­ä¹‰è¡¨ç¤º
  - ç¬¬4æ®µï¼ˆå±‚12ï¼‰ï¼šæœ€ç»ˆç‰¹å¾ï¼Œå…¨å±€è¯­ä¹‰ç†è§£

  2. å¤šå±‚PromptåµŒå…¥æœºåˆ¶

  # æ›¿æ¢ç°æœ‰çš„å•ä¸€prompt_embeddings
  self.multi_layer_prompts = nn.ModuleList([
      nn.Parameter(torch.zeros(1, 16, 768))  # ç¬¬1æ®µï¼š16ä¸ªtokens
      for _ in range(4)  # 4ä¸ªåˆ†æ®µ
  ])

  3. NGAç‰¹å¾èšåˆï¼ˆé€‚é…ViT-B/32ï¼‰

  # é‚»åŸŸé«˜æ–¯èšåˆå…¬å¼
  W_s,l = exp(-((d-l+1)Â²)/(2ÏƒÂ²))
  Z_s = Î£(H_l Â· W_s,l)  # Ïƒ=1.0ä¸ºç»éªŒæœ€ä¼˜å€¼

  ğŸ› ï¸ å®ç°æ­¥éª¤è¯¦è§£

  æ­¥éª¤1: ä¿®æ”¹LaFTerUFTç±»ç»“æ„

  class MultiLayerLaFTerUFT(LaFTerUFT):
      def __init__(self, cfg, classnames, clip_model):
          # ä¿æŒåŸæœ‰åˆå§‹åŒ–
          super().__init__(cfg, classnames, clip_model)

          # å¤šå±‚prompté…ç½®
          self.num_stages = 4  # 4ä¸ªåˆ†æ®µ
          self.stage_layers = [[1,2,3,4], [5,6,7,8], [9,10,11], [12]]
          self.prompt_tokens_per_stage = 16  # æ¯æ®µ16ä¸ªtoken

          # å¤šå±‚promptå‚æ•°
          self.multi_prompts = nn.ModuleList([
              nn.Parameter(torch.zeros(1, self.prompt_tokens_per_stage, 768))
              for _ in range(self.num_stages)
          ])

          # NGAèšåˆæƒé‡
          self.nga_sigma = nn.Parameter(torch.ones(self.num_stages))

          # æ®µé—´èåˆæƒé‡
          self.stage_weights = nn.Parameter(torch.ones(self.num_stages) / self.num_stages)

  æ­¥éª¤2: å®ç°åˆ†æ®µpromptæ³¨å…¥

  def forward_multi_stage_prompts(self, image_features):
      stage_outputs = []

      for stage_idx, layers in enumerate(self.stage_layers):
          # åœ¨æ¯æ®µå¼€å§‹æ³¨å…¥å¯¹åº”çš„prompt
          if stage_idx == 0:
              # ç¬¬ä¸€æ®µï¼šåœ¨patch embeddingåæ³¨å…¥
              x = self.inject_prompt_at_stage(image_features, stage_idx)
          else:
              # åç»­æ®µï¼šåœ¨ä¸­é—´å±‚æ³¨å…¥
              x = self.inject_prompt_between_layers(x, stage_idx, layers[0])

          # é€šè¿‡è¯¥æ®µçš„transformer layers
          stage_feature = self.forward_through_stage(x, layers)

          # NGAèšåˆè¯¥æ®µå†…çš„å¤šå±‚ç‰¹å¾
          aggregated_feature = self.nga_aggregate(stage_feature, stage_idx)
          stage_outputs.append(aggregated_feature)

      return stage_outputs

  æ­¥éª¤3: NGAèšåˆå®ç°

  def nga_aggregate(self, stage_features, stage_idx):
      """é‚»åŸŸé«˜æ–¯èšåˆæœºåˆ¶"""
      sigma = self.nga_sigma[stage_idx]
      layers_in_stage = len(self.stage_layers[stage_idx])

      weights = []
      for l in range(layers_in_stage):
          # é«˜æ–¯æƒé‡è®¡ç®—
          w = torch.exp(-((layers_in_stage - l) ** 2) / (2 * sigma ** 2))
          weights.append(w)

      weights = torch.stack(weights)
      weights = weights / weights.sum()  # å½’ä¸€åŒ–

      # åŠ æƒèšåˆ
      aggregated = sum(w * feat for w, feat in zip(weights, stage_features))
      return aggregated

  æ­¥éª¤4: çº§è”åˆ¤åˆ«å™¨

  def cascade_classifier(self, stage_outputs):
      """èåˆå¤šæ®µç‰¹å¾è¿›è¡Œæœ€ç»ˆåˆ†ç±»"""
      # å¯¹æ¯æ®µè¾“å‡ºè¿›è¡Œæ ‡å‡†åŒ–
      normalized_outputs = [F.layer_norm(out, out.shape[-1:]) for out in stage_outputs]

      # å¯å­¦ä¹ çš„æ®µé—´æƒé‡èåˆ
      final_feature = sum(w * feat for w, feat in
                         zip(self.stage_weights, normalized_outputs))

      # é€šè¿‡åŸæœ‰çš„text classifier
      logits = self.text_classifier(final_feature)
      return logits, stage_outputs  # è¿”å›ä¸­é—´è¾“å‡ºç”¨äºç›‘ç£

  ğŸ¯ è®­ç»ƒç­–ç•¥è®¾è®¡

  æ¸è¿›å¼è®­ç»ƒæµç¨‹

  def progressive_training_strategy():
      """
      é˜¶æ®µ1 (Epochs 1-2): Warm-up
      - åªè®­ç»ƒç¬¬4æ®µï¼ˆæœ€æ·±å±‚ï¼‰çš„promptå’Œclassifier
      - å†»ç»“å…¶ä»–æ‰€æœ‰å‚æ•°

      é˜¶æ®µ2 (Epochs 3-5): é€æ®µè§£å†»
      - ä»æ·±åˆ°æµ…é€æ­¥è§£å†»å„æ®µprompt
      - ç¬¬4æ®µ â†’ ç¬¬3æ®µ â†’ ç¬¬2æ®µ â†’ ç¬¬1æ®µ

      é˜¶æ®µ3 (Epochs 6-8): å…¨å±€fine-tune
      - æ‰€æœ‰multi_prompts + NGAå‚æ•° + stage_weights
      - å­¦ä¹ ç‡: 1e-4 (prompt) + 1e-5 (NGA)
      """

  ğŸ’¡ å…³é”®ä¼˜åŒ–ç‚¹

  1. é’ˆå¯¹æƒ…æ„Ÿè¯†åˆ«çš„ç‰¹æ®Šè®¾è®¡

  - ä½å±‚æ®µï¼šå…³æ³¨é¢éƒ¨å¾®è¡¨æƒ…ã€è‚¢ä½“åŠ¨ä½œç»†èŠ‚
  - ä¸­å±‚æ®µï¼šæ•è·é¢éƒ¨æ•´ä½“è¡¨æƒ…æ¨¡å¼
  - é«˜å±‚æ®µï¼šç†è§£æƒ…æ„Ÿè¯­ä¹‰å’Œä¸Šä¸‹æ–‡

  2. ä¸ç°æœ‰åŒä»»åŠ¡æŸå¤±çš„é›†æˆ

  # ä¿æŒåŸæœ‰çš„åŒä»»åŠ¡æŸå¤±ï¼Œå¢åŠ å¤šæ®µç›‘ç£
  total_loss = classification_loss + Î» * distribution_loss + Î± * multi_stage_consistency_loss

  3. å‚æ•°æ•ˆç‡ä¼˜åŒ–

  æ–°å¢å‚æ•°é‡ï¼š
  - Multi-prompts: 4 Ã— 16 Ã— 768 = 49,152
  - NGA weights: 4 Ã— 1 = 4
  - Stage weights: 4 Ã— 1 = 4
  æ€»è®¡ï¼š~49Kå‚æ•°ï¼ˆç›¸æ¯”åŸæ¨¡å‹å¢åŠ <0.1%ï¼‰

  ğŸš€ é¢„æœŸæ€§èƒ½æå‡

  1. åˆ†ç±»å‡†ç¡®ç‡ï¼šé¢„æœŸæå‡2-5%ï¼ˆåŸºäºCascade-CLIPå®éªŒç»“æœï¼‰
  2. ç‰¹å¾è¡¨è¾¾ï¼šå¤šå°ºåº¦æƒ…æ„Ÿç‰¹å¾ï¼Œæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›
  3. åˆ†å¸ƒå­¦ä¹ ï¼šæ›´ç²¾å‡†çš„æƒ…æ„Ÿåˆ†å¸ƒé¢„æµ‹
  4. æ¨ç†é€Ÿåº¦ï¼šå‡ ä¹æ— é¢å¤–å¼€é”€ï¼ˆ<5%ï¼‰

  è¿™ä¸ªæ–¹æ¡ˆå®Œå…¨åŸºäºä½ ç°æœ‰çš„LaFTeræ¶æ„ï¼Œå¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„åŒä»»åŠ¡å­¦ä¹ æ¡†æ¶ä¸­ï¼Œå……åˆ†å‘æŒ¥ViT-B/32çš„å¤šå±‚ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚